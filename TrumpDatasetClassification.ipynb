{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 230710 files belonging to 2 classes.\n",
      "Using 184568 files for training.\n",
      "Found 230710 files belonging to 2 classes.\n",
      "Using 46142 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 39\n",
    "sequence_length = 25\n",
    "vocab_size = 4096\n",
    "embedding_dim = 128\n",
    "\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"dataset\", batch_size = batch_size, validation_split = 0.2, \n",
    "    subset = 'training', seed = seed\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"dataset\", batch_size = batch_size, validation_split = 0.2, \n",
    "    subset = 'validation', seed = seed\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size =  AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size =  AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = 'int', \n",
    "    output_sequence_length = sequence_length)\n",
    "\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "181/181 [==============================] - 307s 2s/step - loss: 0.6894 - accuracy: 0.5009 - val_loss: 0.6866 - val_accuracy: 0.4924\n",
      "Epoch 2/25\n",
      "181/181 [==============================] - 235s 1s/step - loss: 0.6835 - accuracy: 0.5036 - val_loss: 0.6822 - val_accuracy: 0.5030\n",
      "Epoch 3/25\n",
      "181/181 [==============================] - 225s 1s/step - loss: 0.6786 - accuracy: 0.5137 - val_loss: 0.6790 - val_accuracy: 0.5146\n",
      "Epoch 4/25\n",
      "181/181 [==============================] - 221s 1s/step - loss: 0.6740 - accuracy: 0.5233 - val_loss: 0.6770 - val_accuracy: 0.5222\n",
      "Epoch 5/25\n",
      "181/181 [==============================] - 228s 1s/step - loss: 0.6695 - accuracy: 0.5316 - val_loss: 0.6752 - val_accuracy: 0.5261\n",
      "Epoch 6/25\n",
      "181/181 [==============================] - 221s 1s/step - loss: 0.6649 - accuracy: 0.5405 - val_loss: 0.6719 - val_accuracy: 0.5315\n",
      "Epoch 7/25\n",
      "181/181 [==============================] - 233s 1s/step - loss: 0.6603 - accuracy: 0.5492 - val_loss: 0.6706 - val_accuracy: 0.5347\n",
      "Epoch 8/25\n",
      "181/181 [==============================] - 241s 1s/step - loss: 0.6558 - accuracy: 0.5568 - val_loss: 0.6703 - val_accuracy: 0.5373\n",
      "Epoch 9/25\n",
      "181/181 [==============================] - 220s 1s/step - loss: 0.6514 - accuracy: 0.5644 - val_loss: 0.6690 - val_accuracy: 0.5416\n",
      "Epoch 10/25\n",
      "181/181 [==============================] - 241s 1s/step - loss: 0.6471 - accuracy: 0.5715 - val_loss: 0.6691 - val_accuracy: 0.5452\n",
      "Epoch 11/25\n",
      "181/181 [==============================] - 210s 1s/step - loss: 0.6429 - accuracy: 0.5776 - val_loss: 0.6681 - val_accuracy: 0.5486\n",
      "Epoch 12/25\n",
      "181/181 [==============================] - 212s 1s/step - loss: 0.6387 - accuracy: 0.5839 - val_loss: 0.6666 - val_accuracy: 0.5525\n",
      "Epoch 13/25\n",
      "181/181 [==============================] - 229s 1s/step - loss: 0.6345 - accuracy: 0.5899 - val_loss: 0.6664 - val_accuracy: 0.5601\n",
      "Epoch 14/25\n",
      "181/181 [==============================] - 201s 1s/step - loss: 0.6303 - accuracy: 0.5959 - val_loss: 0.6655 - val_accuracy: 0.5668\n",
      "Epoch 15/25\n",
      "181/181 [==============================] - 210s 1s/step - loss: 0.6261 - accuracy: 0.6013 - val_loss: 0.6660 - val_accuracy: 0.5729\n",
      "Epoch 16/25\n",
      "181/181 [==============================] - 213s 1s/step - loss: 0.6218 - accuracy: 0.6066 - val_loss: 0.6672 - val_accuracy: 0.5776\n",
      "Epoch 17/25\n",
      "181/181 [==============================] - 225s 1s/step - loss: 0.6176 - accuracy: 0.6123 - val_loss: 0.6681 - val_accuracy: 0.5773\n",
      "Epoch 18/25\n",
      "181/181 [==============================] - 232s 1s/step - loss: 0.6133 - accuracy: 0.6173 - val_loss: 0.6700 - val_accuracy: 0.5763\n",
      "Epoch 19/25\n",
      "181/181 [==============================] - 211s 1s/step - loss: 0.6089 - accuracy: 0.6230 - val_loss: 0.6688 - val_accuracy: 0.5795\n",
      "Epoch 20/25\n",
      "181/181 [==============================] - 210s 1s/step - loss: 0.6045 - accuracy: 0.6287 - val_loss: 0.6704 - val_accuracy: 0.5759\n",
      "Epoch 21/25\n",
      "181/181 [==============================] - 208s 1s/step - loss: 0.6000 - accuracy: 0.6335 - val_loss: 0.6712 - val_accuracy: 0.5785\n",
      "Epoch 22/25\n",
      "181/181 [==============================] - 206s 1s/step - loss: 0.5954 - accuracy: 0.6385 - val_loss: 0.6756 - val_accuracy: 0.5778\n",
      "Epoch 23/25\n",
      "181/181 [==============================] - 200s 1s/step - loss: 0.5908 - accuracy: 0.6437 - val_loss: 0.6769 - val_accuracy: 0.5811\n",
      "Epoch 24/25\n",
      "181/181 [==============================] - 201s 1s/step - loss: 0.5860 - accuracy: 0.6492 - val_loss: 0.6779 - val_accuracy: 0.5822\n",
      "Epoch 25/25\n",
      "181/181 [==============================] - 200s 1s/step - loss: 0.5811 - accuracy: 0.6543 - val_loss: 0.6800 - val_accuracy: 0.5835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee42802730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class EmbeddingInitializer(tf.keras.initializers.Initializer):\n",
    "    def __call__(self, shape=None, dtype=None, **kwargs):\n",
    "        weights = tf.convert_to_tensor(np.load('w2vVectors.npy'))\n",
    "        return weights\n",
    "\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer = EmbeddingInitializer(),\n",
    "                            mask_zero= True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "model.fit(train_ds, epochs=25,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=30, \n",
    "                    callbacks = tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001EE3F65BB20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001EE3F659910> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hi this is a VCS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e111ae3915571b6edef858e479b1eab8559f9d45ac36164e1de90516ae344ee5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
